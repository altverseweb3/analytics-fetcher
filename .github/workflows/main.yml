name: Analytics Data Aggregation

on:
  schedule:
    # Run every 6 hours (at minutes 0 past hours 0, 6, 12, 18)
    - cron: "0 */6 * * *"
  workflow_dispatch:
    # Allow manual triggering

jobs:
  aggregate-analytics:
    runs-on: ubuntu-latest
    env:
      ANALYTICS_API_KEY: ${{ secrets.ANALYTICS_API_KEY }}
      ALTVERSE_API_URL: ${{ secrets.ALTVERSE_API_URL }}
      VERCEL_DEPLOY_HOOK_URL: ${{ secrets.VERCEL_DEPLOY_HOOK_URL }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Run analytics fetcher and write to analytics.json
        run: |
          # Run the python script to write to analytics.json
          python analytics_fetcher.py

          # Ensure file exists and is named correctly
          if [ ! -f analytics.json ]; then
            echo "Error: analytics.json not found after script execution."
            exit 1
          fi

      - name: Configure Git
        run: |
          git config --local user.email "analytics-fetcher[bot]@users.noreply.github.com"
          git config --local user.name "analytics-fetcher[bot]"

      - name: Commit and push if changed
        run: |
          git add analytics.json
          if git diff --quiet && git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "chore: update analytics data $(date +'%Y-%m-%d %H:%M:%S')"
            git push
          fi

      - name: Wait for GitHub synchronization
        run: sleep 10s

      - name: Trigger Vercel Deployment
        run: |
          curl -X POST "$VERCEL_DEPLOY_HOOK_URL"
